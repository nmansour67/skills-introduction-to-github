{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNfSBp24pf9nNKRvLuLmAUB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmansour67/skills-introduction-to-github/blob/main/First_Causal_Inference_Model_step1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoSNtJewVHik",
        "outputId": "b095fdf3-73d5-4d29-911a-b5fac7e60aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Generated.\n",
            "Average Severity of Treated: 6.121680873315007\n",
            "Average Severity of Untreated: 4.6951766537856106\n",
            "Mortality Rate (Treated): 42.2%\n",
            "Mortality Rate (Untreated): 38.6%\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Section 2: The “RWE Foundry” Protocol\n",
        "\n",
        "\n",
        "\n",
        "How do you build this engine? You need a Propensity Score Matching (PSM) pipeline.\n",
        "\n",
        "The Problem with Real Data: It is biased.\n",
        "\n",
        "If you compare patients who got \"AI Treatment\" vs. \"No AI,\" you might find the AI patients did worse.\n",
        "\n",
        "Why? Because doctors might have used the AI only on the sickest patients.\n",
        "\n",
        "The Fix: You must mathematically \"match\" patients to create a synthetic randomized trial.\n",
        "\n",
        "\n",
        "\n",
        "Section 3: Technical Workshop, Your First Causal Inference Model\n",
        "\n",
        "\n",
        "\n",
        "Target Audience: The Data Scientist, The MD-PhD, The Curious Skeptic.\n",
        "\n",
        "\n",
        "\n",
        "We are going to solve the \"Selection Bias\" problem. We will generate a dataset where a new \"AI Protocol\" looks like it kills people, not because of anything other than it was used on sicker patients. Then, we will use Propensity Score Matching (PSM) to prove that it actually saves lives.\n",
        "\n",
        "Step 1: Generate the \"Confounded\" Dataset Open Google Colab. We created 1,000 patients.\n",
        "\n",
        "The Sicker Patients: Older, more comorbidities. They are more likely to get the AI Protocol, because doctors are worried.\n",
        "\n",
        "The Truth: The AI Protocol reduces mortality risk by 20%.\n",
        "\n",
        "\n",
        "\n",
        "Now let’s go back to coding, the technical part of the equation of empowering the healthcare professional. A short recap on how it works, and the terminology. The Python computer code is the language in which we communicate with the machine; it is the way we give it orders and tell the machine what we want to do or implement in terms of statistical methods, mathematical models, data analysis, and much more. These machines have been trained to use these methods and analysis protocols. We just need to trigger these machines and order what to do. Consider a big coffee machine that is trained to do 9 various types of coffee: ristretto, espresso, macchiato, americano, cappuccino, cafe latte, glace, and frappe. The machine does not produce you a cup of coffee of your choice, unless you order it to do so, and provide it with your choice. Same thing with the machines, or the artificial intelligence machines that we are dealing with. First, we start by writing the code. For this, and since we do not have the technical expertise in writing code, we now have the privilege of communicating with LLMs using our human natural language, telling these LLMS what we exactly want, one, two, three, etc... LLMs will be generating our code in Python. All we have to do is copy the code generated, and paste it in Google Colab environment, in the cell that is automatically open [+ Code], and if it is not open yet, just choose it from the menu. Once paste the code, click on [Run] or [Run All]. The machine will work automatically, conduct all the statistical, mathematical, or data analysis models that you have included in the Python code, and generate results. Sometime, the code is not a perfect code. No worries! Google Colab is augmented with “Gemini”, the Google AI LLM tool that can help in diagnosing the parts that are not working, proposing modifications, and asking you whether you wanted these modifications to be implemented or not. If you choose the “yes”, modify and run, Gemini will affect the modifications to the code, so it is a new corrected code, and run the code again. Most probably you shall get results. If not, expect Gemini to propose other modifications and run the code again, but surely it will run perfectly from the first modification. Here comes your role, not in the technical part certainly, not in writing and modifying the code, but rather in analyzing the results, the outcomes of running the code. Here comes your role, be it a physician, nurse, student in training, or a research scientist. You are the only one who has the know-how, how to scrutinize and pick up the anomalies in the data analysis report, and here is your power. Our promise is to empower you with AI tools, so AI can do the technical part on your behalf, but run it as per your directions and plans, then comes your role as a scientist, as the one who have the know-how and expertise in your own field to judge the outcomes. Here comes your role as Customer Zero, so let us play that role.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# Python\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "n_patients = 1000\n",
        "\n",
        "\n",
        "\n",
        "# 1. Generate Covariates (Patient Features)\n",
        "\n",
        "age = np.random.normal(65, 10, n_patients)\n",
        "\n",
        "severity_score = np.random.normal(5, 2, n_patients) # Apache II Score\n",
        "\n",
        "\n",
        "\n",
        "# 2. Determine who gets the \"AI Protocol\" (Treatment Assignment)\n",
        "\n",
        "# Doctors give the AI tool to SICKER, OLDER patients.\n",
        "\n",
        "# Logistic function to determine probability of treatment\n",
        "\n",
        "prob_treatment = 1 / (1 + np.exp(-(0.1 * age + 0.5 * severity_score - 10)))\n",
        "\n",
        "treatment = np.random.binomial(1, prob_treatment)\n",
        "\n",
        "\n",
        "\n",
        "# 3. Simulate Outcome (Mortality)\n",
        "\n",
        "# Base Risk + Age/Severity Risk - TREATMENT BENEFIT (The AI helps!)\n",
        "\n",
        "# Notice the -0.8 coefficient for treatment (It saves lives)\n",
        "\n",
        "mortality_risk = 1 / (1 + np.exp(-(0.05 * age + 0.3 * severity_score - 0.8 * treatment - 5)))\n",
        "\n",
        "outcome = np.random.binomial(1, mortality_risk)\n",
        "\n",
        "\n",
        "\n",
        "df = pd.DataFrame({\n",
        "\n",
        "    'Age': age,\n",
        "\n",
        "    'Severity': severity_score,\n",
        "\n",
        "    'Treated_with_AI': treatment,\n",
        "\n",
        "    'Mortality': outcome\n",
        "\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "print(\"Dataset Generated.\")\n",
        "\n",
        "print(\"Average Severity of Treated:\", df[df['Treated_with_AI']==1]['Severity'].mean())\n",
        "\n",
        "print(\"Average Severity of Untreated:\", df[df['Treated_with_AI']==0]['Severity'].mean())\n",
        "\"\"\"\n",
        "Step 2: The \"Naive\" Analysis (The Trap) If you just compare mortality rates, what do you see?\n",
        "\"\"\"\n",
        "\n",
        "# Python\n",
        "\n",
        "# Naive comparison\n",
        "\n",
        "mortality_treated = df[df['Treated_with_AI']==1]['Mortality'].mean()\n",
        "\n",
        "mortality_untreated = df[df['Treated_with_AI']==0]['Mortality'].mean()\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Mortality Rate (Treated): {mortality_treated*100:.1f}%\")\n",
        "\n",
        "print(f\"Mortality Rate (Untreated): {mortality_untreated*100:.1f}%\")"
      ]
    }
  ]
}